# Neuroscope:An Explainable AI Toolbox for Semantic Segmentation and Image Classification of Convolutional Neural Nets
Trust in artificial intelligence (AI) predictions is a crucial point for a widespread acceptance
of new technologies, especially in sensitive areas like autonomous driving. The need for tools
explaining AI for deep learning of images is thus eminent. Our proposed toolbox Neuroscope
addresses this demand by offering state-of-the-art visualization algorithms for image classification
and newly adapted methods for semantic segmentation of convolutional neural nets (CNNs). With
its easy to use graphical user interface (GUI), it provides visualization on all layers of a CNN. Due to
its open model-view-controller architecture, networks generated and trained with Keras and PyTorch
are processable, with an interface allowing extension to additional frameworks. We demonstrate the
explanation abilities provided by Neuroscope using the example of traffic scene analysis.


# Cite
If you use this code for your research, please cite as:
```
@Article{app11052199,
AUTHOR = {Schorr, Christian and Goodarzi, Payman and Chen, Fei and Dahmen, Tim},
TITLE = {Neuroscope: An Explainable AI Toolbox for Semantic Segmentation and Image Classification of Convolutional Neural Nets},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {2199},
URL = {https://www.mdpi.com/2076-3417/11/5/2199},
ISSN = {2076-3417},
ABSTRACT = {Trust in artificial intelligence (AI) predictions is a crucial point for a widespread acceptance of new technologies, especially in sensitive areas like autonomous driving. The need for tools explaining AI for deep learning of images is thus eminent. Our proposed toolbox Neuroscope addresses this demand by offering state-of-the-art visualization algorithms for image classification and newly adapted methods for semantic segmentation of convolutional neural nets (CNNs). With its easy to use graphical user interface (GUI), it provides visualization on all layers of a CNN. Due to its open model-view-controller architecture, networks generated and trained with Keras and PyTorch are processable, with an interface allowing extension to additional frameworks. We demonstrate the explanation abilities provided by Neuroscope using the example of traffic scene analysis.},
DOI = {10.3390/app11052199}
}
```
